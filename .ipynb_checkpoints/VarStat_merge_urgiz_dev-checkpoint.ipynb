{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variability Statistics on full FP LCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is meant to serve as a place to develop code whose purpose is to provide ugriz extinction-corrected brightness measures (fpsfMeanCorr, N), with a few basic variability parameters ($\\chi^{2}_{DOF}(f)$, $f\\mu_{full}(f)$, $\\sigma_{full}(f)$), saved as FaintFP_NCSA_variability.csv \n",
    "\n",
    "To do that we :\n",
    "- read in 6 cols per patch-filter \n",
    "- merge ugriz data from the patch \n",
    "- add ebv info\n",
    "- correct for extinction\n",
    "- keep only extinction-corrected mean magnitudes, N, and var params\n",
    "- save all patches as  N_objects (rows) x 6 columns * 5 filters as a single file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessary imports \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from pandas import compat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get E(B-V) \n",
    "DirEBV = '/astro/store/scratch/tmp/suberlak/S13Agg/'\n",
    "ebv = pd.read_csv(DirEBV+'medianPhotometry.csv', usecols=['objectId','ebv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_patch(patch='00_21', ebv = ebv, varPatchesDF = None):\n",
    "    \n",
    "    print('Combining ugriz variability results from patch %s'%patch)\n",
    "    \n",
    "    # Directory storing the results of full LC statistics...\n",
    "    DirStat =  '/astro/store/scratch/tmp/suberlak/s13_stripe82/forced_phot_lt_23/NCSA/Var/'\n",
    "    \n",
    "    # only read columns that we use to speed up execution.... \n",
    "    columns = ['objectId','N','chi2DOF','muFull','sigmaFull','psfMean']\n",
    "\n",
    "    # Read in all filters per patch ... \n",
    "    varPatch = {}\n",
    "    for filter in 'ugriz':\n",
    "        File = 'Var'+filter+patch+'.csv'\n",
    "        varPatch[filter] = pd.read_csv(DirStat+File, usecols = columns)\n",
    "\n",
    "    # Check if each patch-filter file has exactly the same number of objects... \n",
    "    for filter in 'ugriz':\n",
    "        print('Number of unique objectId in %s is %d'%(filter, len(np.unique(varPatch[filter]['objectId'].values))))\n",
    "\n",
    "    # add prefix for each filter, apart from the objectId column  \n",
    "    for filter in 'ugriz':\n",
    "        varPatch[filter].columns = [filter+col  if col != 'objectId' else col for col in varPatch[filter]]\n",
    "\n",
    "    # merge ugriz  \n",
    "    howmerge='inner' # to avoid those objects which were in one filter but not in the other...\n",
    "    varPatchug = pd.merge(varPatch['u'], varPatch['g'], how=howmerge, on='objectId', copy=True, indicator=False)\n",
    "    varPatchugr = pd.merge(varPatchug, varPatch['r'], how=howmerge, on='objectId', copy=True, indicator=False)\n",
    "    varPatchiz = pd.merge(varPatch['i'], varPatch['z'], how=howmerge, on='objectId', copy=True, indicator=False)\n",
    "    varPatchugriz = pd.merge(varPatchugr, varPatchiz , how=howmerge, on='objectId', copy=True, indicator=False)\n",
    "\n",
    "    # check how many objects have ugriz photometry and extinction information \n",
    "    withEBV = np.sum(np.in1d(varPatchugriz['objectId'].values, ebv['objectId'].values))\n",
    "    allOBJ = len(varPatchugriz['objectId'].values)\n",
    "    print('Of all %d objects with ugriz info, %d have E(B-V) values from medianPhotometry.csv'%(allOBJ, withEBV))\n",
    "\n",
    "    # Now this can be a left merge - I only want objects that can be extinction-corrected \n",
    "    varPatchAll =pd.merge(varPatchugriz, ebv, how='inner', on='objectId', copy=True, indicator=False)\n",
    "\n",
    "    # Correct for extinction \n",
    "    A = [5.155, 3.793, 2.751, 2.086, 1.479]\n",
    "    filters = 'ugriz'\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        label = filters[i] + 'psfMean'\n",
    "        varPatchAll[label+'_corr'] = varPatchAll[label] +  varPatchAll['ebv'] * A[i]\n",
    "\n",
    "    # Drop unnecessary columns with uncorrected magnitudes.... \n",
    "    compat.PY3 = True\n",
    "    varPatchSave = varPatchAll.drop(['u'+'psfMean'], axis=1)\n",
    "\n",
    "    for filter in 'griz':\n",
    "        varPatchSave = varPatchSave.drop(filter+'psfMean', axis=1)\n",
    "\n",
    "    # add a column saying which patch an object comes from...\n",
    "    varPatchSave['patch'] = patch\n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    if varPatchesDF is not None : \n",
    "        varPatchesDF = varPatchesDF.append(varPatchSave)\n",
    "        \n",
    "    else : \n",
    "        varPatchesDF = varPatchSave\n",
    "        \n",
    "    return varPatchesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1522762"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(varPatchesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique objectId in u is 490598\n",
      "Number of unique objectId in g is 490369\n",
      "Number of unique objectId in r is 490175\n",
      "Number of unique objectId in i is 490112\n",
      "Number of unique objectId in z is 490566\n",
      "Of all 489986 objects with ugriz info, 487054 have E(B-V) values from medianPhotometry.csv\n",
      "Number of unique objectId in u is 510658\n",
      "Number of unique objectId in g is 510507\n",
      "Number of unique objectId in r is 510303\n",
      "Number of unique objectId in i is 510288\n",
      "Number of unique objectId in z is 510632\n",
      "Of all 510168 objects with ugriz info, 507160 have E(B-V) values from medianPhotometry.csv\n",
      "Number of unique objectId in u is 531613\n",
      "Number of unique objectId in g is 531478\n",
      "Number of unique objectId in r is 531280\n",
      "Number of unique objectId in i is 531266\n",
      "Number of unique objectId in z is 531601\n",
      "Of all 531147 objects with ugriz info, 528548 have E(B-V) values from medianPhotometry.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'errors' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-5ab89f43432e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'test_few_patches_ugriz_FP_variability.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mvarPatchesDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/astro/apps6/anaconda2.0/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[0;32m   1342\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1344\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/astro/apps6/anaconda2.0/lib/python2.7/site-packages/pandas/formats/format.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1524\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m   1525\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1526\u001b[1;33m                             compression=self.compression)\n\u001b[0m\u001b[0;32m   1527\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/astro/apps6/anaconda2.0/lib/python2.7/site-packages/pandas/io/common.pyc\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path, mode, encoding, compression)\u001b[0m\n\u001b[0;32m    422\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'errors' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run over patches : \n",
    "varPatchesDF=  process_patch(patch='00_21', ebv = ebv, varPatchesDF = None)\n",
    "\n",
    "# NCSA patches (11)\n",
    "#  '00_21', 22_43', '44_65','66_87', '88_109','110_131', '132_153', '154_175',  '176_181', '365_387', '388_409'\n",
    "\n",
    "# IN2P3 patches (11)\n",
    "#  '155_176', '176_197','197_218', '218_239', '239_260', '260_281', '281_302', \n",
    "#  '302_323','323_344', '344_365', '365_386'\n",
    "\n",
    "for patch in [ '22_43', '44_65','66_87', '88_109','110_131', '132_153', '154_175',  '176_181', '365_387', '388_409' ]:\n",
    "    varPatchesDF=  process_patch(patch=patch, ebv = ebv, varPatchesDF = varPatchesDF)\n",
    "    \n",
    "compat.PY3 = False\n",
    "name = 'test_00_21-44_65_three_patches_ugriz_var.csv'\n",
    "varPatchesDF.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
